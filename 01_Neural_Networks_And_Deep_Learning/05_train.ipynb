{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15ece933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc892e4f",
   "metadata": {},
   "source": [
    "## 1. Sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7350c8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_np(x):\n",
    "    \"\"\"\n",
    "    Compute sigmoid of x.\n",
    "\n",
    "    Arguments:\n",
    "    x -- A scalar\n",
    "\n",
    "    Return:\n",
    "    s -- sigmoid(x)\n",
    "    \"\"\"\n",
    "  \n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b80bd665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_torch(x):\n",
    "    return 1 / (1 + torch.exp(-x))\n",
    "\n",
    "@tf.function\n",
    "def sigmoid_tf(x):\n",
    "    return 1 / (1 + tf.math.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac6a74e",
   "metadata": {},
   "source": [
    "## 2. Sigmoid derivate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8af7374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_derivative_np(x):\n",
    "    \"\"\"\n",
    "    Compute the gradient (also called the slope or derivative) of the sigmoid function with respect to its input x.\n",
    "    You can store the output of the sigmoid function into variables and then use it to calculate the gradient.\n",
    "    \n",
    "    Arguments:\n",
    "    x -- A scalar or numpy array\n",
    "\n",
    "    Return:\n",
    "    ds -- Your computed gradient.\n",
    "    \"\"\"\n",
    "    \n",
    "    return sigmoid_np(x) * (1 - sigmoid_np(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98af5a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_derivate_torch(x):\n",
    "    return sigmoid_torch(x) * (1 - sigmoid_torch(x))\n",
    "\n",
    "@tf.function\n",
    "def sigmoid_derivate_tf(x):\n",
    "    return sigmoid_tf(x) * (1 - sigmoid_tf(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5bf316",
   "metadata": {},
   "source": [
    "## 3. image2vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3aebd04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image2vector(image):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    image -- a numpy array of shape (length, height, depth)\n",
    "    \n",
    "    Returns:\n",
    "    v -- a vector of shape (length*height*depth, 1)\n",
    "    \"\"\"\n",
    "        \n",
    "    return image.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b4ecd2",
   "metadata": {},
   "source": [
    "## 4. Normalised rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "12ea46e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_rows_np(x):\n",
    "    \"\"\"\n",
    "    Implement a function that normalizes each row of the matrix x (to have unit length).\n",
    "    \n",
    "    Argument:\n",
    "    x -- A numpy matrix of shape (n, m)\n",
    "    \n",
    "    Returns:\n",
    "    x -- The normalized (by row) numpy matrix. You are allowed to modify x.\n",
    "    \"\"\"\n",
    "\n",
    "    return x / np.linalg.norm(x, keepdims=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893837ee",
   "metadata": {},
   "source": [
    "## 5. Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1196fc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_np(x):\n",
    "    \"\"\"Calculates the softmax for each row of the input x.\n",
    "\n",
    "    Your code should work for a row vector and also for matrices of shape (m,n).\n",
    "\n",
    "    Argument:\n",
    "    x -- A numpy matrix of shape (m,n)\n",
    "\n",
    "    Returns:\n",
    "    s -- A numpy matrix equal to the softmax of x, of shape (m,n)\n",
    "    \"\"\"\n",
    "    \n",
    "    x_exp = np.exp(x)\n",
    "    s_sum = np.sum(x_exp, axis=1, keepdims=True)\n",
    "    s = x_exp / s_sum\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "149104ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_torch(x):\n",
    "    x_exp = torch.exp(x)\n",
    "    s_sum = torch.sum(x_exp, axis=1, keepdims=True)\n",
    "    s = x_exp / s_sum\n",
    "    return s\n",
    "\n",
    "# torch.nn.Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2e062b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def softmax_tf(x):\n",
    "    x_exp = tf.math.exp(x)\n",
    "    s_sum = tf.math.reduce_sum(x_exp, axis=1, keepdims=True)\n",
    "    s = x_exp / s_sum\n",
    "    return s\n",
    "\n",
    "# tf.nn.softmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7752c9ca",
   "metadata": {},
   "source": [
    "## 6. L1 Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b97498",
   "metadata": {},
   "source": [
    "$$\\begin{align*} & L_1(\\hat{y}, y) = \\sum_{i=0}^{m-1}|y^{(i)} - \\hat{y}^{(i)}| \\end{align*}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "85612425",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L1_np(yhat, y):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    yhat -- vector of size m (predicted labels)\n",
    "    y -- vector of size m (true labels)\n",
    "    \n",
    "    Returns:\n",
    "    loss -- the value of the L1 loss function defined above\n",
    "    \"\"\"\n",
    "\n",
    "    loss = np.sum(np.abs(y - yhat))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1984f6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L1_torch(yhat, y):\n",
    "    return torch.sum(torch.abs(y - yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d5f154b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L1_tf(yhat, y):\n",
    "    return tf.math.reduce_sum(tf.math.abs(y - yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad7af2f",
   "metadata": {},
   "source": [
    "## 7. L2 Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cac26d9",
   "metadata": {},
   "source": [
    "$$\\begin{align*} & L_2(\\hat{y},y) = \\sum_{i=0}^{m-1}(y^{(i)} - \\hat{y}^{(i)})^2 \\end{align*}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c97cec40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L2_np(yhat, y):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    yhat -- vector of size m (predicted labels)\n",
    "    y -- vector of size m (true labels)\n",
    "    \n",
    "    Returns:\n",
    "    loss -- the value of the L2 loss function defined above\n",
    "    \"\"\"\n",
    "    \n",
    "    loss = np.sum(np.square(y - yhat))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9409f775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L2_torch(yhat, y):\n",
    "    return torch.sum(torch.square(y - yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2729d7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L1_tf(yhat, y):\n",
    "    return tf.math.reduce_sum(tf.math.square(y - yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1239c270",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
